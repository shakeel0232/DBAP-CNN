{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakeel0232/PythonCodeCNN/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "370wpFFBz0XO"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "#import ipdb;   ipdb.set_trace()\n",
        "# MyLBP is DBAP Layer\n",
        "class MyLBP(Layer):\n",
        "    def __init__(self, rank=None,kernel_size=None, strides=None,  padding='valid',activation=None, **kwargs):\n",
        "        self.rank = rank\n",
        "        self.kernel_size = (kernel_size, rank,'kernel_size')\n",
        "        self.strides =(strides, rank, 'strides')\n",
        "        self.padding = (padding)\n",
        "        self.activation = (activation)\n",
        "        super(MyLBP, self).__init__(**kwargs)\n",
        "      \n",
        "def get_pixel(img, center, x, y):\n",
        "    \n",
        "    new_value = 0\n",
        "    try:\n",
        "        if img[x][y] >= center:\n",
        "            new_value = 1\n",
        "    except:\n",
        "        pass\n",
        "    return new_value\n",
        "  \n",
        "  \n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(input_shape[1], self.output_dim),\n",
        "                                      initializer='uniform',\n",
        "                                      power_val = [1, 2, 4, 8, 16, 32, 64, 128],\n",
        "                                      new_value = 0,\n",
        "                                      val = 0,\n",
        "                                      val_ar=[],\n",
        "                                      kernel_size=(3, 3),\n",
        "                                     trainable=True)\n",
        "        self.kernal_size=self.add_kernal_size(kernel_size=(3, 3))\n",
        "        \n",
        "        super(MyLBP, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, img):\n",
        "      val_ar.append(get_pixel(img, center, x-1, y+1))     # top_right\n",
        "      val_ar.append(get_pixel(img, center, x, y+1))       # right\n",
        "      val_ar.append(get_pixel(img, center, x+1, y+1))     # bottom_right\n",
        "      val_ar.append(get_pixel(img, center, x+1, y))       # bottom\n",
        "      val_ar.append(get_pixel(img, center, x+1, y-1))     # bottom_left\n",
        "      val_ar.append(get_pixel(img, center, x, y-1))       # left\n",
        "      val_ar.append(get_pixel(img, center, x-1, y-1))     # top_left\n",
        "      val_ar.append(get_pixel(img, center, x-1, y))\n",
        "      val += val_ar[i] * power_val[i]\n",
        "      return (val , self.kernel)\n",
        " \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXLq3Aq3wkt_"
      },
      "source": [
        "def LeNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=120, activation='relu'))\n",
        "    model.add(layers.Dense(units=84, activation='relu'))\n",
        "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "def DBAP_Full_LeNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(MyLBP(6, kernel_size=(3,3),strides=(2,2)))\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=120, activation='relu'))\n",
        "    model.add(layers.Dense(units=84, activation='relu'))\n",
        "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def Pool_LeNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(layers.AveragePooling2D())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "  \n",
        "def DBAP_LeNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(MyLBP(6, kernel_size=(3,3),strides=(2,2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "  \n",
        "def AlexNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(96, (3,3), strides=(2,2), activation='relu', padding='same', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (5,5), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(384, (3,3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(384, (3,3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='tanh'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='tanh'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "def DBAP_Full_AlexNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(96, (3,3), strides=(2,2), activation='relu', padding='same', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(MyLBP(96, kernel_size=(3,3),strides=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (5,5), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(384, (3,3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(384, (3,3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='tanh'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='tanh'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "  \n",
        "def Pool_AlexNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(96, (3,3), strides=(2,2), activation='relu', padding='same', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "  \n",
        "def DBAP_AlexNet_Model():\n",
        "   \n",
        "    model = keras.Sequential()\n",
        "    model.add(Conv2D(96, (3,3), strides=(2,2), activation='relu', padding='same', input_shape=(img_height, img_width, channel,)))\n",
        "    model.add(MyLBP(96, kernel_size=(3,3),strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD6OnwARz8M5"
      },
      "source": [
        "###############MNIST####################################\n",
        "###############MNIST####################################\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D,BatchNormalization,Dropout\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential,Model\n",
        "from keras import backend as K\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import gzip\n",
        "import pandas as pd\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "mean          = [125.307, 122.95, 113.865]\n",
        "std           = [62.9932, 62.0887, 66.7048]\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "img_height=img_rows\n",
        "img_width=img_cols\n",
        "channel=1\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "for i in range(3):\n",
        "        x_train[:,:,i] = (x_train[:,:,i] - mean[i]) / std[i]\n",
        "        x_test[:,:,i] = (x_test[:,:,i] - mean[i]) / std[i]\n",
        "      \n",
        "model = DBAP_Full_AlexNet_Model()\n",
        "print(model.summary())\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.adam(),\n",
        "              metrics=['accuracy'])\n",
        "history_1=model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),    \n",
        "                   )\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def show_accuracy(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'test_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "def show_loss(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "show_accuracy(history_1)\n",
        "show_loss(history_1)\n",
        "\n",
        "\n",
        "print('Batch_size:', batch_size)\n",
        "print('Epochs:', epochs)\n",
        "print('Test loss:', score[0])\n",
        "#print (\"Model took Time to train: \",(end - start)/60,\"Mins\")\n",
        "print (\"Accuracy on test data is: \",score[1]*100,\"%\")\n",
        "\n",
        "\n",
        "##############Confusion Matrix###############################\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "yPred=model.predict(x_test)\n",
        "import numpy as np\n",
        "yPred=np.argmax(yPred,axis=1)\n",
        "prob=model.predict_classes(x_test)\n",
        "\n",
        "tName=['0','1','2','3','4','5','6','7','8','9']\n",
        "#tName=['0','1','2','3','4','5','6','7','8','9']\n",
        "#tName=['airplanes', 'cars', 'birds', 'cats', 'deer', 'dogs', 'frogs', 'horses', 'ships', 'trucks']\n",
        "#tName=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "print(classification_report(np.argmax(y_test,axis=1),yPred,target_names=tName))\n",
        "print(confusion_matrix(np.argmax(y_test,axis=1),yPred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-npuyfkgglu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxeNH1Geggvp"
      },
      "source": [
        "cd /content/drive/My Drive/Research/2020 March /AlexNet/Saved Models/AlexNet with DBAP softmax/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eOJkvQGQA4P"
      },
      "source": [
        "model.save('AlexNet_DBAP_MNIST_SOFTMAX.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zJdZ1kDNq2R"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"AlexNet_DBAP_MNIST_SOFTMAX.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"AlexNet_DBAP_MNIST_SOFTMAX_weights.h5\")\n",
        "print(\"Saved model to disk\")\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTKMtlOvQvHT"
      },
      "source": [
        "# later...\n",
        " from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('AlexNet_DBAP_MNIST_SOFTMAX.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json,custom_objects={'MyLBP': MyLBP()})\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"AlexNet_DBAP_MNIST_SOFTMAX_weights.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N63ALaSjN5q"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# make models\n",
        "knn_1 = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_2 = KNeighborsClassifier(n_neighbors=2)\n",
        "knn_4 = KNeighborsClassifier(n_neighbors=4)\n",
        "knn_8 = KNeighborsClassifier(n_neighbors=8)\n",
        "knn_16 = KNeighborsClassifier(n_neighbors=16)\n",
        "knn_32 = KNeighborsClassifier(n_neighbors=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er9g-EzFjPVF"
      },
      "source": [
        "knn_1.fit(predictions_1, y_test_2)\n",
        "knn_2.fit(predictions_1, y_test_2)\n",
        "knn_4.fit(predictions_1, y_test_2)\n",
        "knn_8.fit(predictions_1, y_test_2)\n",
        "knn_16.fit(predictions_1, y_test_2)\n",
        "knn_32.fit(predictions_1, y_test_2)\n",
        "\n",
        "# predict\n",
        "kn_1_pr = knn_1.predict(prediction_test)\n",
        "kn_2_pr = knn_2.predict(prediction_test)\n",
        "kn_4_pr = knn_4.predict(prediction_test)\n",
        "kn_8_pr = knn_8.predict(prediction_test)\n",
        "kn_16_pr = knn_16.predict(prediction_test)\n",
        "kn_32_pr = knn_32.predict(prediction_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeKdP36HjQ13",
        "outputId": "a6070540-c6f4-4f7c-8687-4ba1e25bc9cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for i in range(1,6):\n",
        "    val = str(pow(2, i))\n",
        "    eval(\"print(\\\"k=\" + val + \":{}\\\".format(accuracy_score(kn_\" + val + \"_pr, y_test)))\")\n",
        "    #eval(\"print(\\\"k=\" + val + \":{}\\\".format(accuracy_score(prediction_test.round(), y_test)))\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k=2:0.9897\n",
            "k=4:0.9909\n",
            "k=8:0.9907\n",
            "k=16:0.9905\n",
            "k=32:0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auUVsZiDRWqn"
      },
      "source": [
        "model_feat = Model(inputs=model.input,outputs=model.get_layer('dense_5').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-53zckdTM_h"
      },
      "source": [
        "feat_test = model_feat.predict(x_test)\n",
        "print(feat_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtmqraKPRZX4",
        "outputId": "4f2e5a7c-fbc6-4017-fe32-6b524382811d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "c1=0.0001\n",
        "c2=0.001\n",
        "c3=0.01\n",
        "c4=0.1\n",
        "c5=1.0\n",
        "c6=10.0\n",
        "c7=100.0\n",
        "c8=1000.0\n",
        "\n",
        "svm1 = SVC(C=c1,kernel='linear')\n",
        "svm2 = SVC(C=c2,kernel='linear')\n",
        "svm3 = SVC(C=c3,kernel='linear')\n",
        "svm4 = SVC(C=c4,kernel='linear')\n",
        "svm5 = SVC(C=c5,kernel='linear')\n",
        "svm6 = SVC(C=c6,kernel='linear')\n",
        "svm7 = SVC(C=c7,kernel='linear')\n",
        "svm8 = SVC(C=c8,kernel='linear')\n",
        "\n",
        "svm1.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm2.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm3.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm4.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm5.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm6.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm7.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm8.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "\n",
        "\n",
        "print('C =',c1,'acc =',svm1.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c2,'acc =',svm2.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c3,'acc =',svm3.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c4,'acc =',svm4.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c5,'acc =',svm5.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c6,'acc =',svm6.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c7,'acc =',svm7.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c8,'acc =',svm8.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C = 0.0001 acc = 11.35\n",
            "C = 0.001 acc = 98.92\n",
            "C = 0.01 acc = 98.92\n",
            "C = 0.1 acc = 98.92\n",
            "C = 1.0 acc = 98.92999999999999\n",
            "C = 10.0 acc = 98.96000000000001\n",
            "C = 100.0 acc = 98.99\n",
            "C = 1000.0 acc = 98.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftcPM3I6Nhv7"
      },
      "source": [
        "svm.score(feat_train,np.argmax(y_train,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ONt-D1-JLh"
      },
      "source": [
        "feat_test = model_feat.predict(x_test)\n",
        "print(feat_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syuGP9Fz-URt"
      },
      "source": [
        "feat_train = model_feat.predict(x_train)\n",
        "print(feat_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3H0Qfzs-NFg"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(C=1.0,kernel='linear')\n",
        "\n",
        "svm.fit(feat_train,np.argmax(y_train,axis=1))\n",
        "\n",
        "print('fitting done !!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4J-AmCp-Y0n"
      },
      "source": [
        "svm.score(feat_train,np.argmax(y_train,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkWKV4Nr8TUR"
      },
      "source": [
        "svm.score(feat_val,np.argmax(y_val,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbKEYORF7qq3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npcSB9dlalFC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJv0dVvTUM1o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEI5G9igUFHt"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "img_rows, img_cols = 28, 28\n",
        "img_height=img_rows\n",
        "img_width=img_cols\n",
        "channel=1\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "#print(input_shape.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdWIlS2eUt3M"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "c1=0.0001\n",
        "c2=0.001\n",
        "c3=0.01\n",
        "c4=0.1\n",
        "c5=1.0\n",
        "c6=10.0\n",
        "c7=100.0\n",
        "c8=1000.0\n",
        "\n",
        "svm1 = SVC(C=c1,kernel='linear')\n",
        "svm2 = SVC(C=c2,kernel='linear')\n",
        "svm3 = SVC(C=c3,kernel='linear')\n",
        "svm4 = SVC(C=c4,kernel='linear')\n",
        "svm5 = SVC(C=c5,kernel='linear')\n",
        "svm6 = SVC(C=c6,kernel='linear')\n",
        "svm7 = SVC(C=c7,kernel='linear')\n",
        "svm8 = SVC(C=c8,kernel='linear')\n",
        "\n",
        "svm1.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm2.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm3.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm4.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm5.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm6.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm7.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "svm8.fit(feat_test,np.argmax(y_test,axis=1))\n",
        "\n",
        "\n",
        "print('C =',c1,'acc =',svm1.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c2,'acc =',svm2.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c3,'acc =',svm3.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c4,'acc =',svm4.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c5,'acc =',svm5.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c6,'acc =',svm6.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c7,'acc =',svm7.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n",
        "print('C =',c8,'acc =',svm8.score(feat_test,np.argmax(y_test,axis=1))*100.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}